{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "279a6fb1-fa52-4b70-83a7-f1e26ecb27d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "851df0ba-061c-46cf-950c-e9fa0e0b34b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Prompt from Template-----\n",
      "messages=[HumanMessage(content='Tell me a joke about cats.')]\n"
     ]
    }
   ],
   "source": [
    "# PART 1: Create a ChatPromptTemplate using a template string\n",
    "template = \"Tell me a joke about {topic}.\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "print(\"-----Prompt from Template-----\")\n",
    "prompt = prompt_template.invoke({\"topic\": \"cats\"})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26ced639-e54f-4be8-85a7-868c5c98e2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Prompt with Multiple Placeholders -----\n",
      "\n",
      "messages=[HumanMessage(content='You are a helpful assistant.\\nHuman: Tell me a funny story about a panda.\\nAssistant:')]\n"
     ]
    }
   ],
   "source": [
    "# PART 2: Prompt with Multiple Placeholders\n",
    "template_multiple = \"\"\"You are a helpful assistant.\n",
    "Human: Tell me a {adjective} story about a {animal}.\n",
    "Assistant:\"\"\"\n",
    "prompt_multiple = ChatPromptTemplate.from_template(template_multiple)\n",
    "prompt = prompt_multiple.invoke({\"adjective\": \"funny\", \"animal\": \"panda\"})\n",
    "print(\"\\n----- Prompt with Multiple Placeholders -----\\n\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ab44e53-dab5-406d-b276-ea6a7317d7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Prompt with System and Human Messages (Tuple) -----\n",
      "\n",
      "messages=[SystemMessage(content='You are a comedian who tells jokes about lawyers.'), HumanMessage(content='Tell me 3 jokes.')]\n"
     ]
    }
   ],
   "source": [
    "# PART 3: Prompt with System and Human Messages (Using Tuples)\n",
    "messages = [\n",
    "    (\"system\", \"You are a comedian who tells jokes about {topic}.\"),\n",
    "    (\"human\", \"Tell me {joke_count} jokes.\"),\n",
    "]\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "prompt = prompt_template.invoke({\"topic\": \"lawyers\", \"joke_count\": 3})\n",
    "print(\"\\n----- Prompt with System and Human Messages (Tuple) -----\\n\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0cb4118-a900-4977-84cf-514ea86d38ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[System]: Bạn là một trợ lý ảo thông minh và thân thiện, có kiến thức rộng về nhiều lĩnh vực. Hãy trả lời các câu hỏi một cách rõ ràng và hữu ích.\n",
      "[Human]: Chào bạn! Bạn có thể giới thiệu về chính mình không?\n",
      "[Ai]: Chào bạn! Tôi là một mô hình ngôn ngữ lớn, được đào tạo bởi Google. Tôi được thiết kế để hỗ trợ bạn với thông tin, trả lời câu hỏi và tham gia vào các cuộc trò chuyện.\n",
      "[Human]: Thời tiết hôm nay ở Hà Nội thế nào?\n",
      "[Human]: Vậy, nhiệt độ trung bình ở Hà Nội vào tháng 6 là bao nhiêu?\n"
     ]
    }
   ],
   "source": [
    "# PART 4: Prompt with MessagesPLaceholder (helping AI to handle the history of the conversation)\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "conversation_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', \"Bạn là một trợ lý ảo thông minh và thân thiện, có kiến thức rộng về nhiều lĩnh vực. Hãy trả lời các câu hỏi một cách rõ ràng và hữu ích.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"), # Đây là nơi lịch sử trò chuyện sẽ được chèn\n",
    "    ('human', \"{current_question}\") # Đây là câu hỏi hiện tại của người dùng\n",
    "])\n",
    "\n",
    "sample_chat_history = [\n",
    "    ('human', \"Chào bạn! Bạn có thể giới thiệu về chính mình không?\"),\n",
    "    ('ai', \"Chào bạn! Tôi là một mô hình ngôn ngữ lớn, được đào tạo bởi Google. Tôi được thiết kế để hỗ trợ bạn với thông tin, trả lời câu hỏi và tham gia vào các cuộc trò chuyện.\"),\n",
    "    ('human', \"Thời tiết hôm nay ở Hà Nội thế nào?\")\n",
    "]\n",
    "\n",
    "user_current_query = \"Vậy, nhiệt độ trung bình ở Hà Nội vào tháng 6 là bao nhiêu?\"\n",
    "\n",
    "final_messages_for_llm = conversation_prompt.invoke({\n",
    "    \"chat_history\": sample_chat_history,\n",
    "    \"current_question\": user_current_query\n",
    "})\n",
    "\n",
    "for message in final_messages_for_llm.messages:\n",
    "    print(f\"[{message.type.capitalize()}]: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "488dabb4-cdf7-4086-843e-3ce09ff3b062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Bạn là một trợ lý ảo thông minh và thân thiện, có kiến thức rộng về nhiều lĩnh vực. Hãy trả lời các câu hỏi một cách rõ ràng và hữu ích.'), HumanMessage(content='Chào bạn! Bạn có thể giới thiệu về chính mình không?'), AIMessage(content='Chào bạn! Tôi là một mô hình ngôn ngữ lớn, được đào tạo bởi Google. Tôi được thiết kế để hỗ trợ bạn với thông tin, trả lời câu hỏi và tham gia vào các cuộc trò chuyện.'), HumanMessage(content='Thời tiết hôm nay ở Hà Nội thế nào?'), HumanMessage(content='Vậy, nhiệt độ trung bình ở Hà Nội vào tháng 6 là bao nhiêu?')])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_messages_for_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e8d4fa3-ba8b-476b-a19f-ff037090a6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\envs\\learn_langchain\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.  Why did the lawyer bring a ladder to the court case?  Because he wanted to get to the bottom of the case!  (…and also maybe because he couldn\\'t find the elevator.)\\n\\n2.  What\\'s the difference between a lawyer and a pizza?  A pizza can feed a family of four.\\n\\n3.  I saw a lawyer arguing with a vending machine.  I thought, \"Wow, even *machines* are tired of his excuses.\"\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "model = ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
    "\n",
    "result = model.invoke(prompt)\n",
    "result.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_langchain",
   "language": "python",
   "name": "learn_langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
